---
title: "MATH 216 Homework 2"
author: "Alison Cook"
output: html_document
---

```{r, echo=FALSE, message=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(foreign))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(knitr))
```


## Admistrative:

Please indicate

* Who you collaborated with: Jacob Dixon and Carter Merenstein
* Roughly how much time you spent on this HW: ~15 hours
* What gave you the most trouble: 1. Figuring out what the question from the book was asking and what the "right" answer is. 2. The second part is so open-ended, I'm having trouble knowing what to spend time on and how to present my findings in a way that makes sense.
* Any comments you have: Once again, the homework has just taken up so much of my week--I am struggling with how open ended it is and knowing when to stop.







## Question 1:

Question 4 on page 76 from Chapter 4 of Data Analysis Using Regression and
Multilevel/Hierarchical Models.  The codebook can be found
[here](http://www.stat.columbia.edu/~gelman/arm/examples/pollution/pollution.txt).
I've included R code blocks for each question, but use them only if you feel it
necessary.

```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
url <- "http://www.stat.columbia.edu/~gelman/arm/examples/pollution/pollution.dta"
pollution <- read.dta(url) %>% 
  tbl_df()
```

### a) Create a scatterplot of mortality rate versus level of nitric oxides. Do you think a linear regression will fit these data well? Fit the regression and evaluate a residual plot from the regression.

```{r, echo=FALSE, fig.width=12, fig.height=6}

g <- ggplot(data = pollution, aes(x = nox, y = mort)) +
  geom_point() +
  labs(title = "Mortality Rate vs. Nitric Oxide Levels", 
       x = "Relative Nitric Oxide Level", y =    "Mortality rate per 100,000") +
  geom_smooth(method = "lm")
g

model1 <- lm(mort ~ nox, data=pollution)
kable(summary(model1)$coeff, digits = 3)


model_1_res <- resid(model1)
model_1_fit <- fitted(model1)

ggplot(data = pollution, aes(x = nox, y = model_1_res)) +
  geom_point() +
  labs(title = "Residuals vs. Nitric Oxide Levels", 
       x = "Relative Nitric Oxide Levels", y = "Residuals")

ggplot(data = NULL, aes(x = model_1_fit, y = model_1_res)) +
  geom_point() +
  labs(title = "Residuals vs. Fitted Values", 
       x = "Fitted Values", y = "Residuals")
```
A linear regression does not fit the un-transformed nitric oxide level data well, as it is mostly squished in the range 0-100. As shown by the linear model (illustrated on the first graph), there is a huge error range, and the line fits very poorly. The residuals plot shows a similar pattern (all squished to one side) rather than being randomly dispersed, so we can conclude that this model is a poor fit to the data. 


### b) Find an appropriate transformation that will result in data more appropriate for linear regression. Fit a regression to the transformed data and evaluate the new residual plot. 

```{r, echo=FALSE, fig.width=12, fig.height=6}
pollution <- mutate(pollution, log_nox = log10(nox))

l <- ggplot(pollution, aes(x = log_nox, y = mort)) +
  geom_point() +
  labs(title = "Mortality Rate vs. Log of Nitric Oxide Levels", 
       x = "Log of Nitric Oxide Levels", y = "Mortality rate per 100,000") +
  geom_smooth(method = "lm")

l


model2 <- lm(mort ~ log_nox, data=pollution)
kable(summary(model2)$coef, digits = 3)


model_2_res <- resid(model2)
model_2_fit <- fitted(model2)

ggplot(data = pollution, aes(x = log_nox, y = model_2_res)) +
  geom_point() +
  labs(title = "Residuals vs. Log of Nitric Oxide Levels", 
       x = "Log of Relative Nitric Oxide Levels", y = "Residuals")

ggplot(data = NULL, aes(x = model_2_fit, y = model_2_res)) +
  geom_point() +
  labs(title = "Residuals vs. Fitted Values", 
       x = "Fitted Values", y = "Residuals")

```
By log-transforming the nitric oxide pollution potential, the values are re-scaled to represent the spread better. The model fitted to the transformed data has a much smaller standard error and fits the full range of values. A plot of the residuals shows no distinct pattern, meaning that the model explains variation in the data evenly. 


### c) Interpret the slope coefficient from the model you chose in (b).


```{r, echo=FALSE, fig.width=12, fig.height=6}
b <- confint(model2)
kable(b, digits = 3)
```

The slope coefficient of the model predicts that for each increase of 10^x in NOX, there is a 35.311x increase in mortality, within the confidence interval [4.911, 65.712].


### d) Now fit a model predicting mortality rate using levels of nitric oxides, sulfur dioxide, and hydrocarbons as inputs. Use appropriate transformations when helpful. Plot the fitted regression model and interpret the coefficients

```{r, echo=FALSE, fig.width=12, fig.height=6}

ggplot(data=pollution, aes(x=hc, y=mort)) + geom_point()+
  labs(title = "Mortality Rate vs. Hydrocarbon Pollution Potential",
       x = "Relative Hydrocarbon Pollution", y = "Mortality rate per 100,000")

ggplot(data=pollution, aes(x=so2, y=mort)) + geom_point() +
  labs(title = "Mortality Rate vs. Sulphur Dioxide Potential",
       x = "Relative Sulphur Dioxide Pollution", y = "Mortality rate per 100,000")

```
Both graphs show an uneven distribution of data, with most data points squished in the first quarter of the x-axis range. Hydrocarbon and SO2 data should be transformed before fitting a linear model. 


```{r, echo=FALSE, fig.width=12, fig.height=6}

ggplot(data = pollution, aes(x = hc, y = mort)) +
  scale_x_log10() +
  geom_point() +
  geom_smooth(method ="lm") +
  labs(title = "Mortality Rate vs. Log of Hydrocarbon Pollution Potential",
       x = "Log of Relative Hydrocarbon Pollution", y = "Mortality rate per 100,000")

ggplot(data = pollution, aes(x = so2, y = mort)) +
  geom_point() +
  scale_x_log10() +
  geom_smooth(method ="lm") +
  labs(title = "Mortality Rate vs. Log of Sulphur Dioxide Potential",
       x = "Log of Relative Sulphur Dioxide Pollution", y = "Mortality rate per 100,000")

#make log columns for hc and so2
pollution <- pollution %>% 
  mutate(log_hc = log10(hc)) %>% 
  mutate(log_so2 = log10(so2))

#interactions or additive? I think additive because not related

model3 <- lm(mort ~ log_nox + log_hc + log_so2, data=pollution)
kable(summary(model3)$coef, digits = 3)
kable(confint(model3), digits = 3)

ggplot(data = pollution, aes(x=log_nox, y = mort, col=log_hc, size=log_so2)) + 
  geom_point() +
  labs(x = "Log of Nitric Oxide Levels", y = "Mortality rate per 100,000")

```
A regression model that includes three pollutants has additive slope coefficients. The model predicts that for each multiplicative increase of a factor of 10 in nitric oxide, hydrocarbons, and SO2 there is a 134, -132, and 27.1 factor change in mortality, respectively. However, the 95% confidence interval for SO2 includes 0, so it is not a significant predictor in and of itself. 


### e) Cross-validate: fit the model you chose above to the first half of the data and then predict for the second half. (You used all the data to construct the model in (d), so this is not really cross-validation, but it gives a sense of how the steps of cross-validation can be implemented.)

```{r, echo=FALSE, fig.width=12, fig.height=6}

#subset data
set.seed(30)
pollution_build <- pollution %>% sample_frac(0.5)
pollution_predict <- setdiff(pollution, pollution_build)

model3_half <- lm(mort ~ log_nox + log_hc + log_so2, data=pollution_build)

model_3b_pred <- predict(model3_half, pollution_predict)

ggplot(data = pollution_predict, aes(x = mort, y = model_3b_pred)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) +
  labs(title = "Observed vs. Predicted Values: Cross Validation", 
                                    x = "Observed Mortality Rate",
                                    y = "Predicted Mortality Rate")

```
Here, I've used half the data to fit the model generated above, and cross validated it with the second half of the data set. Based on the plot of observed mortality rate vs. predicted mortality rate for the second half of the data, we can see that the model does a mediocre job of predicting the mortality rate based on these three pollutants. If predicted equalled observed data exactly, we would see little to no variability around the line y = x. Here, this is not the case.


### f) What do you think are the reasons for using cross-validation?

Cross validation protects the model from becoming "overfitted". We do not want the model to become so specialized to one specific data set that it cannot be applied to other data of the same type. Cross validation allows us to test the validity of the model on another such data set, rather than the one it was created from.

```{r, echo=FALSE, fig.width=12, fig.height=6}

```







## Question 2:

Perform an Exploratory Data Analysis (EDA) of the OkCupid data, keeping in mind 
in HW-3, you will be fitting a logistic regression to predict gender. What do I mean by
EDA?

* Visualizations
* Tables
* Numerical summaries

For the R Markdown to work, you must first copy the file `profiles.csv` from
Lec09 to the project directory `HW-2`.

```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
profiles <- read.csv("profiles.csv", header=TRUE) %>% tbl_df()
```


### Demographics by Sex
```{r, echo=FALSE, fig.width=12, fig.height=6}
essays <- select(profiles, contains("essay"))
profiles <- select(profiles, -contains("essay"))

#let's see how many many males vs. females are on okcupid
profiles  %>% group_by(sex)  %>% tally() %>% kable()
#looks like there are 800 blank responses here...
#since we are specifically looking to predict gender, let's get rid of those
profiles <- filter(profiles, sex != "")


# Define a binary outcome variable
# y_i = 1 if female
# y_i = 0 if male
profiles <- mutate(profiles, is_female = ifelse(sex=="f", 1, 0))

#ages male and female
# a lot of non-numeric here
x <- as.numeric(as.character(profiles$age))
profiles <- mutate(profiles, age_num = x)

ggplot(data = profiles, aes(age_num)) +
  geom_histogram(aes(y=..density..)) +
  facet_wrap(~sex, nrow = 2) +
  labs(title = "Range of Ages on OKCupid Profiles", 
       x = "Age", y = "Proportion")

#height
ggplot(data=profiles, aes(x=as.numeric(as.character(height)), y=is_female)) +
  geom_jitter(height=0.2, alpha = 0.1) +
  xlim(c(50, 80)) + 
  labs(title = "Range of Heights on Bay Area OKCupid Profiles", x = "Age", y = "Is Female")

#look at reported body types by gender
body_types_gender <- profiles %>% select(body_type, sex) %>% 
  group_by(body_type, sex) %>% tally() %>% arrange(desc(n))

#let's get rid of blank entries
body_types_gender <- body_types_gender[3:26,]

sum <- body_types_gender %>% group_by(sex) %>% summarise(sum(n))
f_tot <- sum[[1,2]]
m_tot <- sum[[2,2]]

body_types_gender <- body_types_gender %>% mutate(prop = 
                                                    ifelse(sex == "f", n/f_tot, 
                                                           ifelse(sex == "m", n/m_tot, NA)))

body_types_gender$body_type <- suppressWarnings(factor(body_types_gender$body_type,levels = 
                                body_types_gender$body_type[order(-body_types_gender$prop)]))


ggplot(body_types_gender, aes(x = body_type, y = prop, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Reported Body Types on Bay Area OKCupid Profiles", 
       x = "Body Type", y = "Proportion of Gender")
```
Since all of this OK Cupid data is self reported, it's important to not potential reporting biases (i.e. someone who is very overweight claims to be "jacked") as well as missing data for several users. The first chart shows the distibution of OK Cupid users by age, proportionally for each gender. Here we see that the distribution is fairly even, with activity climbing and eventually spiking spiking for both men and women just after age 30 (perhaps turning a new decade sparks fear of finding love). The proportion of users 30 and older tapers off into the 50's and 60's. A distribution of heights by gender shows men's heights taller than women as expected. It is interesting to note that the range of heights for men is greater than the range of heights for women. Looking at self-reported body types, we find that men were more likely than women to describe their body as "fit" or "athletic" while women were more likely to describe their body as "curvy", "thin", or "full-figured". I think it is interesting that male and female adjectives for stereotypically undesirable body types are euphemized in different ways. For example, men are likley to describe themselves as "skinny" rather than "thin", or "a little extra", rather than "full-figured". 


### Self-Reported Habits
```{r, echo=FALSE, fig.width=12, fig.height=6}

#look at diet
diet <- profiles %>% select(diet, sex) %>% 
  group_by(diet, sex) %>% tally() %>% arrange(desc(n))

#let's get rid of blank entries
diet <- diet[3:38,]

#summarise some into "other"
common_diet <- c("mostly anything", "anything", "strictly anything", "mostly vegetarian")
other <- diet %>% filter(!(diet %in% common_diet)) %>% group_by(sex) %>% 
 summarise(n = sum(n))

other$diet <- c("other", "other")
other <- other[,c(3,1,2)]

diet <- diet %>% filter(diet %in% common_diet)
diet <- bind_rows(diet, other)

sum <- diet %>% group_by(sex) %>% summarise(sum(n))
f_tot <- sum[[1,2]]
m_tot <- sum[[2,2]]

diet <- diet %>% mutate(prop = 
                            ifelse(sex == "f", n/f_tot, 
                            ifelse(sex == "m", n/m_tot, NA)))

diet$diet <- suppressWarnings(factor(diet$diet, levels = diet$diet[order(-diet$prop)]))

ggplot(diet, aes(x = diet, y = prop, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Reported Diets of Bay Area OKCupid Users", 
       x = "Diet", y = "Proportion of Users by Sex")

#look at whether/how not users drink
drinks <- profiles %>% select(drinks, sex) %>% 
  group_by(drinks, sex) %>% tally() %>% arrange(desc(n))

#let's get rid of blank entries
drinks <- drinks[3:14,]

sum <- drinks %>% group_by(sex) %>% summarise(sum(n))
f_tot <- sum[[1,2]]
m_tot <- sum[[2,2]]

drinks <- drinks %>% mutate(prop = 
                          ifelse(sex == "f", n/f_tot, 
                                 ifelse(sex == "m", n/m_tot, NA)))

drinks$drinks <- factor(drinks$drinks, levels = c("not at all", "rarely", "socially", "often", "very often", "desperately"))


ggplot(drinks, aes(x = drinks, y = prop, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Drinking Habits of Bay Area OKCupid Users",
       x = "Drinking Habit", y = "Proportion of Users by Sex")

#same for drugs
drugs <- profiles %>% select(drugs, sex) %>% 
  group_by(drugs, sex) %>% tally() %>% arrange(desc(n))

#let's get rid of blank entries
drugs <- drugs[3:8,]

sum <- drugs %>% group_by(sex) %>% summarise(sum(n))
f_tot <- sum[[1,2]]
m_tot <- sum[[2,2]]

drugs <- drugs %>% mutate(prop = 
                          ifelse(sex == "f", n/f_tot, 
                                 ifelse(sex == "m", n/m_tot, NA)))


drugs$drugs <- factor(drugs$drugs, levels = c("never", "sometimes", "often"))

ggplot(drugs, aes(x = drugs, y = prop, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Drug Use of Bay Area OKCupid Users",
       x = "Drug Use", y = "Proportion of Users by Sex")


#pets
pets <- profiles %>% select(pets, sex) %>% 
  group_by(pets, sex) %>% tally() %>% arrange(desc(n))


pets <- pets[3:16,] 

sum <- pets %>% group_by(sex) %>% summarise(sum(n))
f_tot <- sum[[1,2]]
m_tot <- sum[[2,2]]

pets <- pets %>% mutate(prop =
                          ifelse(sex == "f", n/f_tot, 
                                 ifelse(sex == "m", n/m_tot, NA))) 

pets$pets <- suppressWarnings(factor(pets$pets , levels = pets$pets [order(-pets$prop)]))

ggplot(pets, aes(x = pets, y = prop, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Pet Preferences of Bay Area OKCupid Users",
       x = "Pet Preference", y = "Proportion of Users by Sex")
```
  
  The charts shown above give a representation of different habits and preferences of OK Cupid users in the San Francisco Bay Area. Once again, these data are the result of self reporting on the internet and should be taken with a grain of salt. Additionally, since responses are optional, I removed blank responses for the analysis. In terms of diet, men were more likely to describe their diet as "strictly anything" while women tended to report eating "mostly vegetarian" diets more frequently than their male counterparts. Both genders strongly favored drinking socially, with men slightly more likely to drink often. Men also tended to use recreational drugs more than women, reporting slightly higher proportions of "sometimes" and "often" responses. Finally, preferences for pets showed that women are more likely to have cats than males, while both genders were most likley to have dogs and no cats. 


```{r, echo=FALSE, fig.width=12, fig.height=6}
#income
#need income to be a numeric
#poor predictor
x <- as.numeric(as.character(profiles$income))
profiles <- mutate(profiles, income_num = x)

ggplot(data=profiles, aes(x=income_num)) +
  geom_histogram(aes(y=..density..)) +
  scale_x_log10() +
  facet_wrap(~sex, nrow =2) +
  labs(title = "Income of Bay Area OKCupid Users by Gender",
       x = "Log of Income (Dollars)", y = "Sex")

ggplot(data = profiles, aes(x = sex, y = income_num)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(title = "Income of Bay Area OKCupid Users", x = "Sex", y = "Log of Income")

kable(profiles %>% group_by(sex) %>% summarise(mean(income_num)), digits = 3)
```
  
  A histogram of log-transformed incomes shows a roughly equal distribution of income. However, a higher proportion of women skew toward the low income side of the scale. The boxplot of income reflects this finding, showing that on average, men make $14,81067 more than women. However, I don't think income is a good predictor of gender because there are too many confounding factors. The majority of users either didn't include income or reported it as $-1, both of which were excluded in the analysis. 


```{r, echo=FALSE, fig.width=12, fig.height=6}
#query essays
# re-load data so it is not mutated at all

profiles <- read.csv("profiles.csv", header=TRUE) %>% tbl_df()
essays <- select(profiles, contains("essay"))
profiles <- select(profiles, -contains("essay"))
profiles <- mutate(profiles, is_female = ifelse(sex=="f", 1, 0))

find.query <- function(char.vector, query){
  which.has.query <- grep(query, char.vector, ignore.case = TRUE)
  length(which.has.query) != 0
}
profile.has.query <- function(data.frame, query){
  query <- tolower(query)
  has.query <- apply(data.frame, 1, find.query, query=query)
  return(has.query)
}

#makeup
profiles$has_makeup <- profile.has.query(data.frame = essays, query = "makeup")
makeup_table <- group_by(profiles, has_makeup) %>% 
  summarise(prop_female=mean(is_female)) %>% spread(has_makeup, prop_female) 

#bakes
profiles$has_baking <- profile.has.query(data.frame = essays, query = "baking")
bakes_table <- group_by(profiles, has_baking) %>% 
  summarise(prop_female=mean(is_female)) %>% spread(has_baking, prop_female)

#heels
profiles$has_heels <- profile.has.query(data.frame = essays, query = "heels")
heels_table <- group_by(profiles, has_heels) %>% 
  summarise(prop_female=mean(is_female)) %>% spread(has_heels, prop_female)

#brunch
profiles$has_brunch <- profile.has.query(data.frame = essays, query = "brunch")
brunch_table <- group_by(profiles, has_brunch) %>% 
  summarise(prop_female=mean(is_female)) %>% spread(has_brunch, prop_female)

female_predict <- bind_rows(makeup_table, bakes_table, heels_table, brunch_table)
female_predict <- as.data.frame(female_predict)
row.names(female_predict) <- c("makeup", "baking", "heels", "brunch")
kable(female_predict)

```

An analysis of frequently used words in user essays shows that women are likely to include "makeup", "baking", "heels", and "brunch" in their profiles. I will say that this portion of the homework was incredibly frustrating and I felt that randomly fishing for "female" words seemed a bit reductive. 


